{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0fZe2wk8R+T0p4pYmUACF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safakatakancelik/rag-system-00-and-eval/blob/master/evaluation/RAG_Evaluation_with_Ragas_%2B_Ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "ldWdKPZvFQHv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cPxDD65GRDCb"
      },
      "outputs": [],
      "source": [
        "# Install Ollama and essential libraries\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "!pip install ragas langchain_ollama datasets langchain_community -q\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start Ollama server in the background\n",
        "subprocess.Popen(['ollama', 'serve'])\n",
        "time.sleep(5) # Give it a moment to wake up\n",
        "\n",
        "# Pull the smarter judge model\n",
        "!ollama pull qwen2.5:7b\n",
        "!ollama pull nomic-embed-text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the eval dataset"
      ],
      "metadata": {
        "id": "TiX9gFgXFcvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "ZphZK_c7ew19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/safakatakancelik/rag-system-00-and-eval/refs/heads/master/evaluation/test_responses.csv\")"
      ],
      "metadata": {
        "id": "6IPm94Lbey9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Evaluation"
      ],
      "metadata": {
        "id": "JoRPw3S1Fi4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "df['contexts'] = df['contexts'].apply(ast.literal_eval) # typecast to list to prevent eval pipeline error\n",
        "eval_dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "acl6ZQNkhUGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from ragas.llms import llm_factory\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import faithfulness, answer_correctness, context_recall\n",
        "from ragas.run_config import RunConfig\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "\n",
        "# Initialize OpenAI-compatible client for Ollama\n",
        "client = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
        "\n",
        "# Use the llm_factory wrapper for the LLM\n",
        "judge_llm = llm_factory(\"qwen2.5:7b\", provider=\"openai\", client=client)\n",
        "\n",
        "# Use the OllamaEmbeddings from langchain\n",
        "judge_embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
        "\n",
        "# Run Configurations to prevent timeouts and parsing errors\n",
        "config = RunConfig(max_workers=1, timeout=600, max_retries=3)\n",
        "\n",
        "# Run Evaluation\n",
        "print(\"Evaluating with Qwen 2.5 7B & Nomic Embeddings...\")\n",
        "results = evaluate(\n",
        "    eval_dataset,\n",
        "    metrics=[faithfulness, answer_correctness, context_recall],\n",
        "    llm=judge_llm,\n",
        "    embeddings=judge_embeddings,\n",
        "    run_config=config\n",
        ")"
      ],
      "metadata": {
        "id": "aJjjkUpGTDde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the evaluation results\n",
        "results_df = pd.DataFrame.from_dict([results])\n",
        "results_df.to_csv(\"EvaluationResults.csv\")"
      ],
      "metadata": {
        "id": "xyX_7PXUWQ65"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}